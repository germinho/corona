{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement de la source de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Racine des fichiers quotidiens\n",
    "BASE_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{}.csv'\n",
    "\n",
    "# Dates de disponibilité des fichiers\n",
    "START_DATE = date(2020, 1, 22)\n",
    "END_DATE = date(2020, 3, 13)\n",
    "\n",
    "# Répertoire de sauvegarde des fichiers bruts\n",
    "RAWFILES_DIR = '../data/raw/'\n",
    "PROCESSED_DIR = '../data/processed/'\n",
    "\n",
    "# Fichier principal\n",
    "ALL_DATA_FILE = 'all_data.csv'\n",
    "\n",
    "#TODO: A remplacer par la lecture du fichier env.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boucle de récupération des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = END_DATE - START_DATE       # as timedelta\n",
    "\n",
    "for i in range(delta.days + 1):\n",
    "    day = START_DATE + timedelta(days=i)\n",
    "    day_label = day.strftime(\"%m-%d-%Y\")\n",
    "    #print(day_label)\n",
    "    virus_df = pd.read_csv(BASE_URL.format(day_label), sep=',', parse_dates=['Last Update'])\n",
    "    virus_df.to_csv(os.path.join(RAWFILES_DIR, day_label + '.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constitution de la table de références lat / log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "df_list = []\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, '*.csv')):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "\n",
    "# Lecture des fichiers récupérés et sélection de ceux qui ont une lat / long\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, '*.csv')):\n",
    "    virus_df = pd.read_csv(file, sep=',')\n",
    "    if 'Latitude' in virus_df.columns and 'Longitude' in virus_df.columns:\n",
    "        df_list.append(virus_df)\n",
    "\n",
    "all_df = pd.concat(df_list)\n",
    "\n",
    "# Création d'une table de références pour les lat/long\n",
    "(all_df[['Province/State', 'Country/Region', 'Latitude', 'Longitude']]\n",
    " .drop_duplicates(subset=['Province/State', 'Country/Region'])\n",
    " .sort_values(by=['Country/Region', 'Province/State'])\n",
    " .to_csv(os.path.join(PROCESSED_DIR, 'lat_long_table.csv'), index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction d'une table unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_catalog = {\n",
    "    'Last Update': ['<M8[ns]'],\n",
    "    'Confirmed': ['float64', 'int64'],\n",
    "    'Deaths': ['float64', 'int64'],\n",
    "    'Recovered': ['float64', 'int64'],\n",
    "    'Latitude': ['float64'],\n",
    "    'Longitude': ['float64'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "latlong_df = pd.read_csv(os.path.join(PROCESSED_DIR, 'lat_long_table.csv'))\n",
    "\n",
    "# Lecture des fichiers récupérés et sélection de ceux qui ont une lat / long\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, '*.csv')):\n",
    "    #print(file)\n",
    "    virus_df = pd.read_csv(file, sep=',')\n",
    "    if ('FIPS' in virus_df.columns):\n",
    "        virus_df = pd.read_csv(file, sep=',', parse_dates=['Last_Update'])\n",
    "        virus_df.columns = ['FIPS','Admin2','Province/State','Country/Region','Last Update','Latitude','Longitude','Confirmed','Deaths','Recovered','Active','Combined_Key']\n",
    "    else:\n",
    "        virus_df = pd.read_csv(file, sep=',', parse_dates=['Last Update'])\n",
    "    if not('Latitude' in virus_df.columns and 'Longitude' in virus_df.columns):\n",
    "        virus_df = virus_df.merge(latlong_df, on=['Province/State', 'Country/Region'], how='left')\n",
    "        \n",
    "    for field, types in data_catalog.items():\n",
    "        assert virus_df[field].dtypes in types, f\"Bad type for {field} in {file}\"\n",
    "        \n",
    "    df_list.append(virus_df.assign(source=os.path.basename(file)))\n",
    "\n",
    "all_df = pd.concat(df_list,sort=False)\n",
    "\n",
    "# Sauvegarde de la table totale\n",
    "all_df.to_csv(os.path.join(PROCESSED_DIR, 'all_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
